import duckdb
import glob
import os
import time

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

INPUT_FOLDER = os.path.join(BASE_DIR, "sorted_request_table", "*.parquet")
OUTPUT_FILE = os.path.join(BASE_DIR, "merged_dedup_requests.parquet")

files = sorted(glob.glob(INPUT_FOLDER))

if not files:
    raise FileNotFoundError("âŒ No sorted parquet files found")

print(f"ğŸ“¦ Found {len(files)} parquet files")

start_total = time.time()

# 1ï¸âƒ£ Count total rows before merge
total_before = duckdb.sql(f"""
SELECT COUNT(*) 
FROM read_parquet({files})
""").fetchone()[0]

print(f"ğŸ“Š Total rows before merge: {total_before:,}")

# 2ï¸âƒ£ Count duplicates
dup_count = duckdb.sql(f"""
SELECT COUNT(*) 
FROM (
    SELECT request_id, request_datetime, COUNT(*) c
    FROM read_parquet({files})
    GROUP BY request_id, request_datetime
    HAVING COUNT(*) > 1
)
""").fetchone()[0]

print(f"âš ï¸ Duplicate groups found: {dup_count:,}")

# 3ï¸âƒ£ Merge + Deduplicate + Export
print("ğŸš€ Merging + removing duplicates...")

duckdb.sql(f"""
COPY (
    SELECT DISTINCT *
    FROM read_parquet({files})
)
TO '{OUTPUT_FILE}';
""")

# 4ï¸âƒ£ Count final rows
total_after = duckdb.sql(f"""
SELECT COUNT(*) 
FROM read_parquet('{OUTPUT_FILE}')
""").fetchone()[0]

removed = total_before - total_after

elapsed = time.time() - start_total

print("\nâœ… DONE")
print(f"ğŸ“‰ Rows removed (duplicates): {removed:,}")
print(f"ğŸ“Š Final row count: {total_after:,}")
print(f"ğŸ“ Output file: {OUTPUT_FILE}")
print(f"â± Time: {elapsed:.2f}s")
